{"scoring":null,"notes":"In the example, the participants made 1, 2, and 3 mistakes respectively, therefore $b=1$ (the smallest of these numbers). Izzy made 3 mistakes, which were not more than $1.3\\cdot b + 100=101.3$, so these outputs are good enough to pass this test case (as are any other valid outputs).","legend":"The popular improv website \\emph{Interpretation Impetus} hosts regular improv\r\ncontests and maintains a rating of the best performers. However, since improv can often go horribly wrong, the website is notorious for declaring improv contests \\emph{unrated}. It now holds a wager before each improv contest where the participants try to predict whether it will be rated or unrated, and they are now more popular than the improv itself.\r\n\r\nIzzy and $n$ other participants take part in each wager. First, they each make\r\ntheir prediction, expressed as \\texttt{1} (``rated'') or \\texttt{0} (``unrated''). Izzy\r\nalways goes last, so she knows the predictions of the other participants when making\r\nher own. Then, the actual competition takes place and it is declared either rated\r\nor unrated.\r\n\r\nYou need to write a program that will interactively play as Izzy. There will be $m$ wagers held in 2021, and Izzy's goal is to have at most\r\n$1.3\\cdot b + 100$ wrong predictions after all those wagers, where $b$ is the \\emph{smallest}\r\nnumber of wrong predictions that any other wager participant will have after all those wagers. \r\n\r\nThe number $b$ is not known in advance. Izzy also knows nothing about\r\nthe other participants~--- they might somehow always guess correctly, or their predictions might be correlated. Izzy's predictions, though, do not affect the predictions of the other participants and the decision on the contest being rated or not~--- in other words, in each test case, your program always receives the same inputs, no matter what it outputs.","authorLogin":"elizarov","language":"english","timeLimit":3000,"output":"","inputFile":"stdin","outputFile":"stdout","input":"","authorName":"Roman Elizarov","sampleTests":[{"output":"\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n1\r\n\r\n\r\n1\r\n\r\n","input":"3 4\r\n000\r\n\r\n1\r\n100\r\n\r\n1\r\n001\r\n\r\n0\r\n111\r\n\r\n1\r\n","inputFile":"example.01","outputFile":"example.01.a"}],"name":"Is It Rated?","interaction":"First, a solution must read two integers $n$ ($1 \\le n \\le 1000$) and $m$ ($1 \\le m \\le 10\\,000$). Then, the solution must process $m$ wagers. For each of them, the solution must first read a string consisting of $n$ \\texttt{0}s and \\texttt{1}s, in which the $i$-th character denotes the guess of the $i$-th participant. Then, the solution must print Izzy's guess as \\texttt{0} or \\texttt{1}.\r\nDon't forget to flush the output after printing it! Then, the solution must read the actual outcome, also as \\texttt{0} or \\texttt{1}, and then proceed to the next wager, if this wasn't the last one. \r\n\r\nYour solution will be considered correct if it makes at most $1.3\\cdot b + 100$ mistakes, where $b$ is the smallest number of mistakes made by any other participant. Note that if a solution outputs anything except \\texttt{0} or \\texttt{1} for a wager, it will be considered incorrect even if it made no other mistakes. \r\n\r\nThere are 200 test cases in this problem.","memoryLimit":536870912,"tutorial":"See https://en.wikipedia.org/wiki/Randomized\\_weighted\\_majority\\_algorithm for more details.\r\n\r\nIntuitively, we want to trust more the predictions of those participants that have already made fewer mistakes. The most radical version of this would be to only trust the participants with the smallest number of mistakes in any given wager; when there are multiple such participants and their predictions differ, we can for example choose the prediction which has the most such ``best participant'' votes behind it. An in case even those are tied, we can flip a coin.\r\n\r\nHowever, it turns out that this solution is not good enough, and trusting just the best participants can backfire. For example, consider the following two wagers with two participants, which can be easily generalized to any even number of participants: 01 (correct 1), then 10 (correct 1). Each participant has made one mistake, while we have made 0.5 mistakes in the first wager on average, plus 1 mistake in the second wager (because the participant which was correct in the first wager makes a mistake there), so we're going to be 1.5 times worse than the worst participant if this is repeated many times, which is not good enough.\r\n\r\nTherefore, we need to make two improvements to the aforementioned solution:\r\n\\begin{itemize}\r\n\\item Instead of just considering the votes of the participants that have made the smallest number of mistakes only, we will assign weight $\\beta^x$ to the vote of a participant that has made $x$ mistakes, where $0 < \\beta < 1$ is some value that we'll choose later.\r\n\\item Instead of choosing the prediction that gets most (weighted) votes, we will choose the prediction randomly, using the fraction of the total vote weight that favors this prediction as the probability of us choosing it.\r\n\\end{itemize}\r\n\r\nYou can check the ``Analysis'' section of the Wikipedia article mentioned above for the (relatively straightforward) proof\r\nthat this approach is now good enough for the appropriate values of $\\beta$. $\\beta=\\frac{3}{4}$ passes with a margin of 6 standard deviations, but any value of $\\beta$ between roughly $\\frac{1}{2}$ and $\\frac{19}{20}$ was good enough.\r\n\r\nNote that in order to avoid floating-point underflow, we should use $\\beta^{x-y}$ instead of just $\\beta^x$ as the vote weights, where $y$ is the smallest number of mistakes that any participant has made so far.\r\n\r\nNote that the judges are not aware of any deterministic solution that passes in this problem. The approach mentioned\r\nin the beginning, where we choose the prediction that has the most weighted votes instead of picking randomly\r\nwith the appropriate probabilities, ends up being almost twice as worse in the case where the votes are split 51/49 in favor\r\nof the wrong prediction every time."}